"""
–ú–æ–¥—É–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—á–µ—Ä–µ–¥—å—é –±–∞—Ç—á–µ–π (3 —Å–ª–æ—Ç–∞).
3-—Å–ª–æ—Ç–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è non-stop –æ–±—Ä–∞–±–æ—Ç–∫–∏.
"""

import asyncio
import time
import base64
import numpy as np
from typing import Dict, Any, Optional
from app.config import load_config
from app.monitoring.logger import setup_logger, log_json
from app.monitoring.metrics import MetricsCollector
from app.pipeline.context_buffer import ContextBuffer
from app.components.groq_whisper import GroqWhisperClient
from app.components.local_whisper import LocalWhisperClient
from app.components.openrouter_llm import OpenRouterClient
from app.components.xtts_engine import XTTSEngine


class BatchQueue:
    """
    3-—Å–ª–æ—Ç–æ–≤–∞—è –æ—á–µ—Ä–µ–¥—å –±–∞—Ç—á–µ–π –¥–ª—è non-stop –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    
    –ö–æ–Ω—Ü–µ–ø—Ü–∏—è:
        Slot 1: PLAYING - –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ
        Slot 2: READY - –ì–æ—Ç–æ–≤ –∫ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—é  
        Slot 3: PROCESSING - –û–±—Ä–∞–±–æ—Ç–∫–∞ (STT ‚Üí LLM ‚Üí TTS)
    
    –ü—Ä–∏–Ω—Ü–∏–ø:
        –ü–æ–∫–∞ Slot 1 –∏–≥—Ä–∞–µ—Ç, Slot 3 –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–π –±–∞—Ç—á.
        –ö–æ–≥–¥–∞ Slot 1 –æ—Å–≤–æ–±–æ–¥–∏–ª—Å—è ‚Üí Slot 2 ‚Üí Slot 1 (playing).
    """
    
    def __init__(self, websocket, whisper_client=None, tts_engine=None, llm_client=None, metrics_collector=None, topic=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–∏ –±–∞—Ç—á–µ–π.

        Args:
            websocket: WebSocket connection
            whisper_client: Preloaded Whisper client (optional)
            tts_engine: Preloaded TTS engine (optional)
            llm_client: Preloaded LLM client (optional)
            metrics_collector: Shared metrics collector (optional)
            topic: Optional topic/context for translation (optional)
        """
        self.config = load_config()["pipeline"]
        self.logger = setup_logger(__name__)
        self.metrics = metrics_collector if metrics_collector else MetricsCollector()
        self.websocket = websocket

        # Use preloaded models if provided, otherwise create new
        if whisper_client:
            self.whisper_client = whisper_client
            self.logger.info("Using preloaded Whisper client")
        else:
            whisper_config = load_config()["models"]["whisper"]
            if whisper_config["provider"] == "local":
                self.whisper_client = LocalWhisperClient()
            else:
                self.whisper_client = GroqWhisperClient()

        if llm_client:
            self.openrouter_client = llm_client
            self.logger.info("Using preloaded LLM client")
        else:
            self.openrouter_client = OpenRouterClient()

        if tts_engine:
            self.xtts_engine = tts_engine
            self.logger.info("Using preloaded TTS engine")
        else:
            self.xtts_engine = XTTSEngine()

        self.context_buffer = ContextBuffer()

        # Topic/context for better translation accuracy
        self.topic = topic

        # –ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê: –û—á–µ—Ä–µ–¥—å –≥–æ—Ç–æ–≤—ã—Ö –±–∞—Ç—á–µ–π (FIFO)
        self.ready_queue = asyncio.Queue()  # –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –≥–æ—Ç–æ–≤—ã—Ö –±–∞—Ç—á–µ–π
        self.playback_task = None  # –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        self.is_running = False

        # NON-STOP PLAYBACK: –ú–∏–Ω–∏–º—É–º –≥–æ—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤ –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        # –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –¥–æ—Å–ª–æ–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ (–º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏)
        self.min_ready_chunks_before_start = self.config.get("min_ready_chunks_before_start", 3)
        self.playback_started = False  # –§–ª–∞–≥ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞

        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.processing_count = 0  # –°–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π —Å–µ–π—á–∞—Å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
        self.processing_lock = asyncio.Lock()  # –î–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏ —Å—á–µ—Ç—á–∏–∫–∞

        # PIPELINE CONCURRENCY CONTROL (–∫–∞–∂–¥—ã–π —ç—Ç–∞–ø –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –±–∞—Ç—á –∑–∞ —Ä–∞–∑)
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–Ω—ã–º –±–∞—Ç—á–∞–º –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ (–∫–æ–Ω–≤–µ–π–µ—Ä)
        self.whisper_semaphore = asyncio.Semaphore(1)  # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –≤ STT
        self.translation_semaphore = asyncio.Semaphore(1)  # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –≤ Translation
        self.tts_semaphore = asyncio.Semaphore(1)  # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –≤ TTS

        # GLOBAL PIPELINE LIMIT: –ú–∞–∫—Å–∏–º—É–º N –±–∞—Ç—á–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        # (Processing + Ready + Playing)
        self.max_concurrent_batches = self.config.get("batch_queue_size", 3)
        self.pipeline_semaphore = asyncio.Semaphore(self.max_concurrent_batches)

        self.logger.info(
            f"BatchQueue initialized (pipeline: max {self.max_concurrent_batches} batches, "
            f"NON-STOP: buffer {self.min_ready_chunks_before_start} chunks before playback, "
            f"STT‚ÜíTranslation‚ÜíTTS‚ÜíPlayback)"
        )
    
    async def add_batch(self, audio_array: np.ndarray) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–∞—Ç—á –∞—É–¥–∏–æ –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É.

        –û–ß–ï–†–ï–î–¨ –° –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï–ú: –ñ–¥–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã–π —Å–ª–æ—Ç –µ—Å–ª–∏ —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
        –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π (batch_queue_size –∏–∑ config).

        –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤ —Å–∏—Å—Ç–µ–º–µ –±—É–¥–µ—Ç –Ω–µ –±–æ–ª—å—à–µ N –±–∞—Ç—á–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        (–æ–±—Ä–∞–±–æ—Ç–∫–∞ + –≥–æ—Ç–æ–≤—ã–µ + –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ).

        Args:
            audio_array: Numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ (float32, 16kHz)
        """
        # –ö–†–ò–¢–ò–ß–ù–û: –ñ–¥–µ–º —Å–≤–æ–±–æ–¥–Ω—ã–π —Å–ª–æ—Ç –≤ pipeline (–±–ª–æ–∫–∏—Ä—É—é—â–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è!)
        # –≠—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ

        # Check if we need to wait (–≤—Å–µ —Å–ª–æ—Ç—ã –∑–∞–Ω—è—Ç—ã)
        if self.pipeline_semaphore._value == 0:
            self.logger.warning(f"‚ö†Ô∏è Pipeline FULL ({self.max_concurrent_batches}/{self.max_concurrent_batches} slots) - waiting for free slot... (processing: {self.processing_count}, ready: {self.ready_queue.qsize()})")

        await self.pipeline_semaphore.acquire()

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –±–∞—Ç—á–µ–π
        async with self.processing_lock:
            self.processing_count += 1

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –í –§–û–ù–ï (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –ë–ï–ó –û–ñ–ò–î–ê–ù–ò–Ø)
        asyncio.create_task(self._process_batch_async(audio_array))

        self.logger.debug(f"Batch queued for processing (total processing: {self.processing_count}, pipeline slots: {self.pipeline_semaphore._value}/{self.max_concurrent_batches})")

    async def _process_batch_async(self, audio_array: np.ndarray) -> None:
        """
        –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π pipeline.

        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á (STT ‚Üí LLM ‚Üí TTS) –∏ –∫–ª–∞–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ ready_queue.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è –¥—Ä—É–≥–∏–µ –±–∞—Ç—á–∏.

        –ö–û–ù–í–ï–ô–ï–†–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê:
        - –ë–∞—Ç—á –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ —ç—Ç–∞–ø—ã: STT ‚Üí Translation ‚Üí TTS
        - –ö–∞–∂–¥—ã–π —ç—Ç–∞–ø –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –±–∞—Ç—á –∑–∞ —Ä–∞–∑ (Semaphore)
        - –†–∞–∑–Ω—ã–µ –±–∞—Ç—á–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

        Args:
            audio_array: Numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ (float32, 16kHz)
        """
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π pipeline (5-10 —Å–µ–∫—É–Ω–¥)
            # process_batch –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—à–∞–≥–æ–≤—ã–µ semaphores –≤–Ω—É—Ç—Ä–∏
            processed = await self.process_batch(audio_array)

            # –ï—Å–ª–∏ process_batch –≤–µ—Ä–Ω—É–ª None (–Ω–∞–ø—Ä. —Ä—É—Å—Å–∫–∞—è —Ä–µ—á—å) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if processed is None:
                self.logger.debug("Batch processing returned None (skipped) - releasing semaphore")
                self.pipeline_semaphore.release()  # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å–ª–æ—Ç —Å—Ä–∞–∑—É
                return

            # –ü–æ–º–µ—á–∞–µ–º, —á—Ç–æ —ç—Ç–æ—Ç –±–∞—Ç—á –∑–∞—Ö–≤–∞—Ç–∏–ª pipeline_semaphore
            # (–Ω—É–∂–Ω–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–æ—Å–ª–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è)
            processed['_pipeline_semaphore_acquired'] = True

            # –ö–ª–∞–¥–µ–º –≥–æ—Ç–æ–≤—ã–π –±–∞—Ç—á –≤ –æ—á–µ—Ä–µ–¥—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            await self.ready_queue.put(processed)

            self.logger.debug("Batch processed and queued for playback")

        except Exception as e:
            self.logger.error(f"Background batch processing failed: {e}")
            self.metrics.record_error("batch_processing_async", str(e))

            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –û–°–í–û–ë–û–ñ–î–ê–ï–ú semaphore —Å—Ä–∞–∑—É (–±–∞—Ç—á –Ω–µ –¥–æ–π–¥–µ—Ç –¥–æ playback)
            self.pipeline_semaphore.release()

        finally:
            # –£–º–µ–Ω—å—à–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –±–∞—Ç—á–µ–π
            async with self.processing_lock:
                self.processing_count -= 1

    async def start_playback_loop(self) -> None:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.

        –≠—Ç–æ—Ç —Ü–∏–∫–ª –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –±–µ—Ä–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –±–∞—Ç—á–∏ –∏–∑ ready_queue
        –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (non-stop).

        –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Å—Å–∏–∏.
        """
        if self.is_running:
            self.logger.warning("Playback loop already running")
            return

        self.is_running = True
        self.playback_task = asyncio.create_task(self._playback_loop())
        self.logger.info("Playback loop started")

    async def _playback_loop(self) -> None:
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ü–∏–∫–ª –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —Å –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–µ–π –¥–ª—è NON-STOP —Ä–µ–∂–∏–º–∞.

        –õ–û–ì–ò–ö–ê NON-STOP:
        1. –ñ–¥—ë—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è min_ready_chunks_before_start –≥–æ—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤ (2-3 —à—Ç)
        2. –ù–∞—á–∏–Ω–∞–µ—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –µ—Å—Ç—å –±—É—Ñ–µ—Ä
        3. –î–∞–ª—å—à–µ –∏–≥—Ä–∞–µ—Ç non-stop –∏–∑ –æ—á–µ—Ä–µ–¥–∏

        –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —á—Ç–æ –ø–æ–∫–∞ –∏–≥—Ä–∞–µ—Ç –æ–¥–∏–Ω —á–∞–Ω–∫, —Å–ª–µ–¥—É—é—â–∏–π —É–∂–µ –≥–æ—Ç–æ–≤!
        """
        self.logger.info("Playback loop running")

        while self.is_running:
            try:
                # –ö–†–ò–¢–ò–ß–ù–û: –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –∂–¥—ë–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –±—É—Ñ–µ—Ä–∞!
                if not self.playback_started:
                    # –ñ–¥—ë–º –ø–æ–∫–∞ –Ω–∞–∫–æ–ø–∏—Ç—Å—è –º–∏–Ω–∏–º—É–º —á–∞–Ω–∫–æ–≤
                    while self.ready_queue.qsize() < self.min_ready_chunks_before_start:
                        current_ready = self.ready_queue.qsize()
                        self.logger.info(
                            f"üîÑ Buffering before playback start: "
                            f"{current_ready}/{self.min_ready_chunks_before_start} chunks ready, "
                            f"{self.processing_count} processing..."
                        )
                        await asyncio.sleep(0.5)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 0.5 —Å–µ–∫

                    self.playback_started = True
                    self.logger.info(
                        f"üöÄ BUFFER READY! Starting NON-STOP playback with "
                        f"{self.ready_queue.qsize()} chunks buffered"
                    )

                # –ë–µ—Ä–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≥–æ—Ç–æ–≤—ã–π –±–∞—Ç—á –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–∂–¥–µ–º –µ—Å–ª–∏ –ø—É—Å—Ç–æ)
                batch = await self.ready_queue.get()

                # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏
                queue_size = self.ready_queue.qsize()
                if queue_size == 0:
                    self.logger.warning(
                        f"‚ö†Ô∏è Queue EMPTY during playback! "
                        f"Processing: {self.processing_count}. May cause gaps!"
                    )

                # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º
                await self._play_batch(batch)

                # –ü–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—É—é
                self.ready_queue.task_done()

            except asyncio.CancelledError:
                self.logger.info("Playback loop cancelled")
                break
            except Exception as e:
                self.logger.error(f"Playback loop error: {e}")

        self.logger.info("Playback loop stopped")

    async def _play_batch(self, batch: Dict[str, Any]) -> None:
        """
        –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –æ–¥–∏–Ω –±–∞—Ç—á (–æ—Ç–ø—Ä–∞–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç—É —á–µ—Ä–µ–∑ WebSocket).

        –ü–æ—Å–ª–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –û–°–í–û–ë–û–ñ–î–ê–ï–¢ —Å–ª–æ—Ç –≤ pipeline (pipeline_semaphore),
        –ø–æ–∑–≤–æ–ª—è—è —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É –Ω–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É.

        Args:
            batch: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –±–∞—Ç—á —Å –ø–æ–ª—è–º–∏:
                - original: –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
                - translated: —Ä—É—Å—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥
                - audio: WAV –±–∞–π—Ç—ã
                - duration: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
        """
        try:
            batch_num = self.metrics.batches_processed + 1
            queue_size = self.ready_queue.qsize()

            self.logger.info(f"=== PLAYING BATCH #{batch_num} (duration: {batch['duration']:.1f}s, queue: {queue_size} waiting) ===")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            await self.websocket.send_json({
                "type": "transcription",
                "text": batch["original"],
                "timestamp": time.time()
            })

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
            await self.websocket.send_json({
                "type": "translation",
                "original": batch["original"],
                "translated": batch["translated"],
                "timestamp": time.time()
            })

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ
            await self.websocket.send_json({
                "type": "audio_output",
                "data": base64.b64encode(batch["audio"]).decode(),
                "duration": batch["duration"],
                "timestamp": time.time()
            })

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics_data = self.metrics.get_summary()
            # Add latency fields compatible with UI expected format:
            # UI expects metrics.latency.stt, etc. Our get_summary returns latency_avg dict.
            # We should map it to the structure the UI expects or ensure UI reads from latency_avg.
            # Looking at app.js: metrics.latency.stt. So we need to ensure metrics_data['latency'] is that dict.
            # metrics.get_summary() returns "latency_avg" key.
            # Let's map it for UI compatibility.
            ui_metrics = {
                "type": "metrics",
                "data": {
                    "latency": metrics_data["latency_avg"],
                    "batches_processed": self.metrics.batches_processed,
                    "uptime": metrics_data["session_duration"],
                    "slots": self.get_status()["slots"]
                }
            }
            await self.websocket.send_json(ui_metrics)

            # –ñ–¥—ë–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            await asyncio.sleep(batch["duration"])

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
            self.metrics.batches_processed += 1

            # FINAL METRICS UPDATE (to show updated batch count)
            final_metrics = self.metrics.get_summary()
            await self.websocket.send_json({
                "type": "metrics",
                "data": {
                    "latency": final_metrics["latency_avg"],
                    "batches_processed": self.metrics.batches_processed,
                    "uptime": final_metrics["session_duration"],
                    "slots": self.get_status()["slots"]
                }
            })

            self.logger.info(f"=== BATCH #{batch_num} DONE (played {batch['duration']:.1f}s) ===")

        finally:
            # –ö–†–ò–¢–ò–ß–ù–û: –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å–ª–æ—Ç –≤ pipeline –ø–æ—Å–ª–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É –Ω–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É (non-stop –∫–æ–Ω–≤–µ–π–µ—Ä)
            if batch.get('_pipeline_semaphore_acquired'):
                self.pipeline_semaphore.release()
                slots_available = self.pipeline_semaphore._value
                self.logger.info(f"‚úÖ Pipeline slot released (available: {slots_available}/{self.max_concurrent_batches}, processing: {self.processing_count}, ready: {self.ready_queue.qsize()})")

    async def stop_playback_loop(self) -> None:
        """
        –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.

        –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Å–µ—Å—Å–∏–∏.
        """
        self.is_running = False
        self.playback_started = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞

        if self.playback_task:
            self.playback_task.cancel()
            try:
                await self.playback_task
            except asyncio.CancelledError:
                pass

        self.logger.info("Playback loop stopped")

    async def process_batch(self, audio_array: np.ndarray) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á —á–µ—Ä–µ–∑ STT ‚Üí LLM ‚Üí TTS pipeline —Å –∫–æ–Ω–≤–µ–π–µ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π.

        –ö–û–ù–í–ï–ô–ï–†–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
        - STEP 1 (STT): –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –∑–∞ —Ä–∞–∑ —á–µ—Ä–µ–∑ whisper_semaphore
        - STEP 2 (Translation): –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –∑–∞ —Ä–∞–∑ —á–µ—Ä–µ–∑ translation_semaphore
        - STEP 3 (TTS): –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –∑–∞ —Ä–∞–∑ —á–µ—Ä–µ–∑ tts_semaphore

        –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–Ω—ã–º –±–∞—Ç—á–∞–º –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:
        - –ë–∞—Ç—á #1: TTS
        - –ë–∞—Ç—á #2: Translation
        - –ë–∞—Ç—á #3: STT

        Args:
            audio_array: –ê—É–¥–∏–æ –º–∞—Å—Å–∏–≤ (float32, 16kHz)

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            # STEP 1: STT (Local Whisper on GPU or Groq)
            # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Whisper –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            async with self.whisper_semaphore:
                start = time.time()
                transcription = await self.whisper_client.transcribe(audio_array)
                stt_duration = time.time() - start
                self.metrics.record_latency("stt", stt_duration)
                self.logger.debug(f"STT completed in {stt_duration:.2f}s")

            # –ë–õ–û–ö–ò–†–û–í–ö–ê –†–£–°–°–ö–û–ô –†–ï–ß–ò: –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥
            detected_lang = transcription.get("language", "unknown").lower()
            if detected_lang in ["ru", "russian", "rus"]:
                self.logger.warning(f"‚õî Russian speech detected - SKIPPING translation: '{transcription['text'][:50]}...'")

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ UI
                await self.websocket.send_json({
                    "type": "russian_detected",
                    "text": transcription["text"],
                    "message": "Russian speech detected - translation skipped",
                    "timestamp": time.time()
                })

                # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É - –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–º, –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º
                return None

            # STEP 2: Translation (OpenRouter + context + topic)
            # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –º–æ–∂–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            async with self.translation_semaphore:
                start = time.time()
                context = await self.context_buffer.get_context()
                translation = await self.openrouter_client.translate(
                    transcription["text"], context, topic=self.topic
                )
                translation_duration = time.time() - start
                self.metrics.record_latency("translation", translation_duration)
                self.logger.debug(f"Translation completed in {translation_duration:.2f}s")

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤)
                await self.context_buffer.add_sentence(transcription["text"])

            # STEP 3: TTS (XTTS-v2)
            # –¢–æ–ª—å–∫–æ 1 –±–∞—Ç—á –º–æ–∂–µ—Ç —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            async with self.tts_semaphore:
                start = time.time()
                audio_bytes = await self.xtts_engine.synthesize(translation)
                tts_duration = time.time() - start
                self.metrics.record_latency("tts", tts_duration)
                self.logger.debug(f"TTS completed in {tts_duration:.2f}s")

            # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –∏–∑ WAV header
            tts_sample_rate = self.xtts_engine.output_sample_rate
            audio_data_size = len(audio_bytes) - 44  # Subtract WAV header
            audio_duration = audio_data_size / (tts_sample_rate * 2)  # 2 bytes/sample (int16)

            # E2E –º–µ—Ç—Ä–∏–∫–∞
            e2e_duration = stt_duration + translation_duration + tts_duration
            self.metrics.record_latency("e2e", e2e_duration)

            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            log_json(self.logger, "INFO", "Batch processed (pipeline)",
                     stt=stt_duration, translation=translation_duration,
                     tts=tts_duration, e2e=e2e_duration)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return {
                "original": transcription["text"],
                "translated": translation,
                "audio": audio_bytes,
                "duration": audio_duration,
                "timestamp": time.time()
            }

        except Exception as e:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É
            self.metrics.record_error("batch_processing", str(e))
            self.logger.error(f"Batch processing failed: {e}")
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—ã—à–µ

    def get_status(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏ (–¥–ª—è UI dashboard).

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:
                {
                    "processing_count": 2,  # –°–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
                    "ready_queue_size": 3,  # –°–∫–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤—ã—Ö –±–∞—Ç—á–µ–π –∂–¥—É—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
                    "playback_active": True,  # –†–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Ü–∏–∫–ª –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
                    "slots": [...]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å UI
                }

        Note:
            –ú–µ—Ç–æ–¥ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å HTTP endpoint.
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Å–µ–≤–¥–æ-—Å–ª–æ—Ç—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å UI
        slots_status = []

        # –≠–º—É–ª–∏—Ä—É–µ–º —Å–ª–æ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if self.is_running:
            slots_status.append({"slot": 1, "status": "playing"})

        ready_count = self.ready_queue.qsize()
        if ready_count > 0:
            slots_status.append({"slot": 2, "status": "ready"})

        if self.processing_count > 0:
            slots_status.append({"slot": 3, "status": "processing"})

        return {
            "processing_count": self.processing_count,
            "ready_queue_size": ready_count,
            "playback_active": self.is_running,
            "slots": slots_status
        }
